<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" />
  <meta property="og:url" content="URL OF THE WEBSITE" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Formula-Driven Data Augmentation and Partial Retinal Layer Copying for Retinal Layer Segmentation</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <!-- 数式を記述するコード -->
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: { equationNumbers: { autoNumber: "AMS" }},
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    },
    "HTML-CSS": { matchFontHeight: false },
    displayAlign: "left",
    displayIndent: "2em"
  });
</script>

</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Formula-Driven Data Augmentation and Partial Retinal Layer
              Copying
              for Retinal Layer Segmentation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                Tsubasa Konno<sup>1</sup>,</span>
              <span class="author-block">
                Takahiro Ninomiya<sup>2</sup>,</span>
              <span class="author-block">
                Kanta Miura<sup>1</sup>,</span>
              <span class="author-block">
                <a href="http://www.aoki.ecei.tohoku.ac.jp/~ito/" target="_blank">Koichi Ito</a><sup>1</sup>,</span>
              <span class="author-block">
                Noriko Himori<sup>2</sup>,</span>
              <span class="author-block">
                Parmanand Sharma<sup>2</sup>,</span>
              <span class="author-block">
                Toru Nakazawa<sup>2</sup>,</span>
              <span class="author-block">
                <a href="http://www.aoki.ecei.tohoku.ac.jp/~aoki/aokij.html" target="_blank">Takafumi
                  Aoki</a><sup>1</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Graduate School of Information Sciences, Tohoku University<br>
                <sup>2</sup>Department of Ophthalmology, Graduate School of Medicine, Tohoku University<br>The 11th
                OMIA
                Workshop on MICCAI 2024</span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2410.01185.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2410.01185" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Major retinal layer segmentation methods from OCT images assume that the retina is flattened in advance,
              and thus cannot always deal with retinas that have changes in retinal structure due to ophthalmopathy
              and/or curvature due to myopia.
              To eliminate the use of flattening in retinal layer segmentation for practicality of such methods, we
              propose novel data augmentation methods for OCT images.
              Formula-driven data augmentation (FDDA) emulates a variety of retinal structures by vertically shifting
              each column of the OCT images according to a given mathematical formula.
              We also propose partial retinal layer copying (PRLC) that copies a part of the retinal layers and pastes
              it into a region outside the retinal layers.
              Through experiments using the OCT MS and Healthy Control dataset and the Duke Cyst DME dataset, we
              demonstrate that the use of FDDA and PRLC makes it possible to detect the boundaries of retinal layers
              without flattening even retinal layer segmentation methods that assume flattening of the retina.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->

  <section class="section hero is-small" id="Content1">
    <div class="hero-body">
      <div class="container is-max-desktop content">
        <div class="columns is-centered">
          <div class="column is-full">
            <div class="content">
              <h2 class="title is-3">Formula-Driven Data Augmentation (FDDA)</h2>
              <div class="level-set has-text-justified">
                <p>
                  Formula-Driven Data Augmentation (FDDA) is a data augmentation method that emulates a variety of
                  retinal structures based on mathematical formulas.
                  It changes the the position, the tilt, and the curvature of the retina by vertically shifting each
                  column of the OCT images according to a
                  given mathematical formula.
                  It increase the variability of retinal shapes in training data.
                  Specifically, FDDA shifts each column of an OCT image according to a simple combination of $N$th-order
                  functions.
                  In FDDA, the image center is the origin of $N$th-order functions, and the amount of pixel shift is
                  determined based on these functions.
                  Since this process only shifts the pixels by the amount of shift determined by simple functions, the
                  labels of the OCT image after data augmentation can be easily obtained by shifting the boundary labels
                  in the same way.
                </p>
              </div>
              <center>
                <!-- <img src="static/images/FDDA_method6.jpg" alt="Overview of FDDA" class="center-image"> -->
                <img src="static/images/FDDA_method6.jpg" style="width:480px; min-width:75%" alt="Overview of FDDA"
                  class="center-image">
                <p style="width:480px; min-width:75%; text-align:left; margin-bottom:0; font-size:0.8em">
                  Fig. 1. Overview of FDDA using only the first-order shift.
                </p>
              </center>
              <center>
                <!-- <img src="static/images/FDDA_images_new.jpg" alt="Examples of FDDA" class="center-image"> -->
                <img src="static/images/FDDA_images_new.jpg" style="width:480px; min-width:75%" alt="Examples of FDDA"
                  class="center-image">
                <p style="width:480px; min-width:75%; text-align:left; margin-bottom:0; font-size:0.8em">
                  Fig. 2. Examples of applying FDDA to OCT images, where each of the zeroorder, first-order,
                  and second-order shifts is applied to the input image for simplicity: (a) the zero-order shift, (b)
                  the first-order shift, (c) the second-order shift, and (d) the combined shift, and an example of
                  applying RandomAffine for comparison.
                  Colored lines on each image indicate the annotated boundaries between the retinal layers.
                </p>
              </center>
            </div>
          </div>
        </div>
      </div>
  </section>

  <section class="section hero is-small is-light" id="Content2">
    <div class="hero-body">
      <div class="container is-max-desktop content">
        <div class="columns is-centered">
          <div class="column is-full">
            <div class="content">
              <h2 class="title is-3">Partial Retinal Layer Copying (PRLC)</h2>
              <div class="level-set has-text-justified">
                <p>
                  Partial Retinal Layer Copying (PRLC) is a data augmentation method that reproduces the background
                  noise
                  of OCT images, and reduces false detection in the background region.
                  Specifically, PRLC copies a part of the retinal layers and pastes it into a region outside the retinal
                  layers.
                  The parameters in PRLC are the number of retinal layers $l$ to be copied and the width $W$ of the
                  retinal layers.
                  In this paper, $l$ is set to 1 to 3 and $W$ is set to 20 to $N_2$, which are selected at random from
                  the
                  corresponding ranges.
                  First, the target retinal layer is randomly determined and the adjacent retinal layers are selected
                  according to $l$.
                  Next, the retinal layer region to be copied is determined according to $W$.
                  Then, we paste the above retinal layer region at a random position in the background region where no
                  retinal layer labels are assigned.
                  If there is no space in the background region to paste the retinal layer region, we repeat the process
                  from the first step.
                </p>
              </div>
              <center>
                <!-- <img src="static/images/PRLC_images_new.jpg" alt="Examples of PRLC" class="center-image"> -->
                <img src="static/images/PRLC_images_new.jpg" style="width:480px; min-width:75%" alt="Examples of PRLC"
                  class="center-image">
                <p style="width:480px; min-width:75%; text-align:left; margin-bottom:0; font-size:0.8em">
                  Fig. 3. Examples of applying PRLC to OCT images, where the red dashed box indicates the pasted
                  retinal layer area.
                  An example of applying CutMix is also shown for comparison.
                  Colored lines on each image indicate the annotated boundaries between the retinal layers.
                </p>
              </center>
            </div>
          </div>
        </div>
      </div>
  </section>

  <section class="section hero is-small" id="Content3">
    <div class="hero-body">
      <div class="container is-max-desktop content">
        <div class="columns is-centered">
          <div class="column is-full">
            <div class="content">
              <h2 class="title is-3">Evaluation</h2>
              <div class="level-set has-text-justified">
                <p>
                  We demonstrate the effectiveness of the proposed method for retinal layer
                  segmentation by applying FDDA and PRLC to conventional methods.
                  We use the OCT MS and Healthy Control (MSHC) dataset and the Duke Cyst DME (Duke DME) dataset in the
                  experiments.
                  The accuracy of each method is evaluated by the mean absolute distance (MAD) between the detected
                  boundary and the ground truth.
                </p>
                <center>
                  <p style="width:480px; min-width:75%; text-align:left; margin-bottom:0; font-size:0.8em">
                    Table 1. Experimental results of each method for MSHC dataset and Duke DME dataset.
                    The units for MAD are $\mu$m.</p>
                  <img src="static/images/result.svg" style="width:480px; min-width:75%" alt="result"
                    class="center-image">
                </center>
                </p>
              </div>
            </div>
          </div>
        </div>
      </div>
  </section>

  <!-- Paper poster -->
  <!-- <section class="hero is-small"> -->
  <section class="section hero is-small is-light" id="Content4">
    <div class="hero-body">
      <div class="container">
        <h2 class="title">Slide</h2>

        <iframe src="static/images/OMIA-31-main.pdf" width="100%" height="550">
        </iframe>

      </div>
    </div>
  </section>
  <!--End paper poster -->

  <!-- Paper poster -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title">Poster</h2>

        <iframe src="static/images/OMIA2024_Poster_31.pdf" width="100%" height="550">
        </iframe>

      </div>
    </div>
  </section>
  <!--End paper poster -->

  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @article{Konno-OMIA-2024,
          author     = "Konno, T. and Ninomiya, T. and Miura, K. and Ito, K. and Himori, N. and Sharma, P. and Nakazawa, T. and Aoki, T.",
          title      = "Formula-Driven Data Augmentation and Partial Retinal Layer Copying for Retinal Layer Segmentation",
          journal    = "Proc. Ophthalmic Medical Image Analysis Workshop on MICCAI",
          year       = "2024",
          month      = oct
        }
      </code></pre>
    </div>
  </section>
  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the source code of this website, we just ask that you link back to this page in
              the
              footer. <br> This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>